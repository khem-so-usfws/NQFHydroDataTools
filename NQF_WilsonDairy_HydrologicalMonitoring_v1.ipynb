{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "### NQF_WilsonDairy_HydrologicalMonitoring_v1.py\n",
    "### Version: 6/8/2021\n",
    "### Author: Khem So, khem_so@fws.gov, (503) 231-6839\n",
    "### Abstract: This Python 3 script pulls data from the Wilson Dairy Hydrological Data V2 ArcGIS Online feature service (collected via Survey123) and summarizes the data to match an Excel template."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import arcpy\n",
    "import pandas as pd\n",
    "from arcgis import GIS\n",
    "import time, os, fnmatch, shutil\n",
    "import openpyxl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "### ArcGIS Online stores date-time information in UTC by default. This function uses the pytz package to convert time zones and can be used to convert from UTC (\"UTC\") to localized time. For example, localized \"US/Pacific\" is either Pacific Standard Time UTC-8 or Pacific Daylight Time UTC-7 depending upon time of year.\n",
    "from datetime import datetime\n",
    "from pytz import timezone\n",
    "def change_timezone_of_field(df, source_date_time_field, new_date_time_field_suffix, source_timezone, new_timezone):\n",
    "    \"\"\"Returns the values in *source_date_time_field* with its timezone converted to a new timezone within a new field *new_date_time_field*\n",
    "    : param df: The name of the spatially enabled or pandas DataFrame containing datetime fields\n",
    "    : param source_date_time_field: The name of the datetime field whose timezone is to be changed\n",
    "    : param new_date_time_field_suffix: Suffix appended to the end of the name of the source datetime field. This is used to create the new date time field name.\n",
    "    : param source_timezone: The name of the source timezone\n",
    "    : param new_timezone: The name of the converted timezone. For possible values, see https://gist.github.com/heyalexej/8bf688fd67d7199be4a1682b3eec7568\n",
    "    \"\"\"\n",
    "    # Define the source timezone in the source_date_time_field\n",
    "    df[source_date_time_field] = df[source_date_time_field].dt.tz_localize(source_timezone)\n",
    "    # Define the name of the new date time field\n",
    "    new_date_time_field = source_date_time_field + new_date_time_field_suffix\n",
    "    # Convert the datetime in the source_date_time_field to the new timezone in a new field called new_date_time_field\n",
    "    df[new_date_time_field] = df[source_date_time_field].dt.tz_convert(new_timezone)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Alternative to change_timezone_of_field function. This function assumes that a source datetime field is UTC and then will calculate a UTC offset (number of hours) on a new datetime field.\n",
    "from datetime import datetime, timedelta, timezone\n",
    "def utc_offset_timezone_of_field(df, source_date_time_field, new_date_time_field_suffix, new_timezone_utc_offset):\n",
    "    \"\"\"Returns the values in *source_date_time_field* with its timezone converted to a new timezone within a new field *new_date_time_field*\n",
    "    : param df: The name of the spatially enabled or pandas DataFrame containing datetime fields\n",
    "    : param source_date_time_field: The name of the datetime field whose timezone is to be changed\n",
    "    : param new_date_time_field_suffix: Suffix appended to the end of the name of the source datetime field. This is used to create the new date time field name.\n",
    "    : param new_timezone_utc_offset: Number of hours offset from UTC. For example Pacific Standard Time is -8.\n",
    "    \"\"\"\n",
    "    # Define the UTC offset\n",
    "    offset_tz = timezone(timedelta(hours=new_timezone_utc_offset))\n",
    "    offset_td = timedelta(hours=new_timezone_utc_offset)\n",
    "    # Define the name of the new date time field\n",
    "    new_date_time_field = source_date_time_field + new_date_time_field_suffix\n",
    "    # Create a temporary offset field\n",
    "    df['Offset_temp'] = offset_td\n",
    "    # Calculate the new_date_time_field based arithmetic on the source_date_time_field\n",
    "    df[new_date_time_field] = df[source_date_time_field] + df['Offset_temp']\n",
    "    # Define timezone for new_date_time_field\n",
    "    df[new_date_time_field] = df[new_date_time_field].dt.tz_localize(offset_tz)\n",
    "    # Define the source timezone in the source_date_time_field\n",
    "    df[source_date_time_field] = df[source_date_time_field].dt.tz_localize('UTC')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Allow authentication via login to U.S. Fish & Wildlife Service ArcGIS Online account via ArcGIS Pro\n",
    "gis = GIS(\"pro\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Enter path for local file saving\n",
    "# uncomment next line to use ArcGIS interface, otherwise hard coding out_workspace\n",
    "# out_workspace = arcpy.GetParameterAsText(0)\n",
    "out_workspace = \"C:/Users/kso/Desktop/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Create timestamp for file naming\n",
    "t = time.localtime()\n",
    "timestamp = time.strftime('%Y-%m-%d_%H%M', t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Paths to ArcGIS Online data\n",
    "# To populate Service ItemId, go to Feature Service webpage and in bottom right corner, click on the View link.\n",
    "# Current Feature Service webpage: https://fws.maps.arcgis.com/home/item.html?id=c6b4f8f33b804dea8c2232c3d7786e9f\n",
    "ServiceItemID = gis.content.get(\"c6b4f8f33b804dea8c2232c3d7786e9f\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### There are separate methods for pulling spatial versus non-spatial data into Python. Spatial layers will become Spatially Enabled DataFrame objects. \n",
    "## Define variables pointing to spatial layers\n",
    "WilsonHydroMonitoringLyr = ServiceItemID.layers[0]\n",
    "## Create Spatially Enabled DataFrame objects\n",
    "sedfHydroAllData = pd.DataFrame.spatial.from_layer(WilsonHydroMonitoringLyr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(sedfHydroAllData.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Create Metadata sheet\n",
    "# Initialize blank metadata dataframe and add columns\n",
    "metadata = pd.DataFrame(columns = ['Sheet', 'Description'])\n",
    "\n",
    "# Add records to metadata dataframe using the .loc function\n",
    "metadata.loc[0] = [\"Staff Gage\",\"Nisqually NWR Dempsey Creek Staff Gage at Wilson Dairy\"]\n",
    "metadata.loc[1] = [\"Piez P1 East\",\"Nisqually NWR Wilson Dairy - Piezometer P1 (East). Tapedown measurements are made from the measuring point marked on the top of the piezometer. Piezometer 1 (East) Stick-up = 2.57\"]\n",
    "metadata.loc[2] = [\"Piez P2 Central\",\"Nisqually NWR Wilson Dairy - Piezometer P2 (Central). Tapedown measurements are made from the measuring point marked on the top of the piezometer. Piezometer 2 (Central) Stick-up = 2.81\"]\n",
    "metadata.loc[3] = [\"Piez P3 West\",\"Nisqually NWR Wilson Dairy - Piezometer P3 (West). Tapedown measurements are made from the measuring point marked on the top of the piezometer. Piezometer 3 (West) Stick-up = 2.87\"]\n",
    "metadata.loc[4] = [\"Culverts\",\"Nisqually NWR Dephi Road Culverts at Wilson Dairy. Measurements are taken from a measuring point marked on the top of each culvert pipe. Culvert 1 (East) Diameter = 4.97. Culvert 2 (Central) Diameter = 6.0. Culvert 3 (West) Diameter = 6.0. \"]\n",
    "metadata.loc[5] = [\"Locations & MP Elevations\",\"Nisqually NWR Staff Gage, Piezometer, and Culvert Locations and Measuring Point Elevations at Wilson Dairy. Location Datum: NAD83(2011); Vertical Datum: NAVD88\"]\n",
    "metadata.loc[6] = [\"Water Elevation Data, NAVD88\",\"Nisqually NWR Wilson Dairy - Water Elevation Data (NAVD88)\"]\n",
    "metadata.loc[7] = [\"WL Data, Gage Datum\",\"Nisqually NWR Wilson Dairy - Water Elevation Data (Gage Datum). 0 on Staff Gage = 138.899\"]\n",
    "metadata.loc[8] = [timestamp + \" AGOL Data\",\"ArcGIS Online Data Download\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Create Locations and MP Elevations sheet\n",
    "# Initialize blank dataframe and add columns\n",
    "locations = pd.DataFrame(columns = ['Site Name', 'Latitude','Longitude', 'Elevation of M.P. (Ft)', 'Notes', 'identifier'])\n",
    "\n",
    "# Add records to metadata dataframe using the .loc function\n",
    "locations.loc[0] = [\"Dempsey Creek Stilling Well\",46.96455946,-123.02094791,141.413,\"Stilling well is immediately adjacent to the staff gage (within 2 ft of gage).\", \"\"]\n",
    "locations.loc[1] = [\"Dempsey Creek Staff Gage\",46.96455946,-123.02094791,138.899,\"GPS coordinates from stilling well are utilized here due to the proximity of well and gage. Elevation value is for 0 on the staff gage and is based upon the average of two RTK shots\", \"dempsey_creek_gauge\"]\n",
    "locations.loc[2] = [\"Piezometer 1 (East)\",46.96451927,-123.02189070,142.905,\"\", \"piezometer_1_east\"]\n",
    "locations.loc[3] = [\"Piezometer 2 (Central)\",46.96443652,-123.02280777,143.152,\"\", \"piezometer_2_central\"]\n",
    "locations.loc[4] = [\"Piezometer 3 (West)\",46.96405927,-123.02394417,144.686,\"\", \"piezometer_3_west\"]\n",
    "locations.loc[5] = [\"Culvert 1 (East)\",46.96475993,-123.02207761,141.484,\"\", \"culvert_1_east\"]\n",
    "locations.loc[6] = [\"Culvert 2 (Central)\",46.96475841,-123.02219930,142.315,\"This culvert is the western-most of two culverts at this location.\", \"culvert_2_middle\"]\n",
    "locations.loc[7] = [\"Culvert 3 (West)\",46.96476425,-123.02310604,143.114,\"This culvert is the western-most of two culverts at this location.\", \"culvert_3_west\"]\n",
    "locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## Alternative 1: Use change_timezone_of_field function to convert all datetime fields in dataframe from UTC to Pacific within new field with _Pacific suffix\n",
    "# for col in sedfHydroAllData.columns:\n",
    "#     if sedfHydroAllData[col].dtype == 'datetime64[ns]':\n",
    "#         change_timezone_of_field(sedfHydroAllData, col, \"_Pacific\", \"UTC\", \"US/Pacific\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Alternative 2: Use utc_offset_timezone_of_field function to convert all datetime fields in dataframe from UTC to PST within new field with _PST suffix\n",
    "for col in sedfHydroAllData.columns:\n",
    "    if sedfHydroAllData[col].dtype == 'datetime64[ns]':\n",
    "        utc_offset_timezone_of_field(sedfHydroAllData, col, '_PST', -8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Check data types\n",
    "sedfHydroAllData.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Check datetime data\n",
    "sedfHydroAllData.select_dtypes(include=['datetime64[ns, UTC]','datetime64[ns, US/Pacific]'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Archive AGOL Data\n",
    "sedfHydroAllDataArchive = sedfHydroAllData.copy()\n",
    "# Convert Python date time into format Excel can read more easily\n",
    "archive_dt_field_list = sedfHydroAllDataArchive.select_dtypes(include=['datetime64[ns, UTC]','datetime64[ns, US/Pacific]'])\n",
    "for col in archive_dt_field_list:\n",
    "    sedfHydroAllDataArchive[col] = sedfHydroAllDataArchive[col].dt.strftime('%m/%d/%Y %H:%M:%S %Z%z')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define sort order\n",
    "sedfHydroAllData = sedfHydroAllData.sort_values(by=['todays_date_PST'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert Python date time into format Excel can read more easily\n",
    "datefield_list = sedfHydroAllData[['todays_date_PST']]\n",
    "\n",
    "for col in datefield_list:\n",
    "    sedfHydroAllData[col] = sedfHydroAllData[col].dt.strftime('%m/%d/%Y')\n",
    "\n",
    "timefield_list = sedfHydroAllData[['UTC_Time_Measured_4', 'UTC_Time_Measured_1', 'UTC_Time_Measured_2', 'time_logger_pulled_UTC_time', 'time_logger_re_deployed_UTC_t', 'UTC_Time_Measured_3', 'UTC_Time_Measured_4_PST', 'UTC_Time_Measured_1_PST', 'UTC_Time_Measured_2_PST', 'time_logger_pulled_UTC_time_PST', 'time_logger_re_deployed_UTC_t_PST', 'UTC_Time_Measured_3_PST']]\n",
    "\n",
    "for col in timefield_list:\n",
    "    sedfHydroAllData[col] = sedfHydroAllData[col].dt.strftime('%H:%M')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Subset data for Dempsey Creek Staff Gage at Wilson Dairy, Nisqually NWR\n",
    "\n",
    "# Select data based on 2 conditions: measurement type = piezometer and location = dempsey creek gauge OR measurement type = dempsey creek level quick survey\n",
    "# Select columns and reset in desired order\n",
    "sedfHydroStaffGageData = sedfHydroAllData.loc[((sedfHydroAllData['Measurement_Type'] == \"piezometers\") & (sedfHydroAllData['Location__logger'] == \"dempsey_creek_gauge\")) | ((sedfHydroAllData['Measurement_Type'] == \"dempsey_creek_level_quick_surve\")), ['todays_date_PST', 'UTC_Time_Measured_4_PST', 'observers', 'observers_other', 'creek_gauge_ft', 'UTC_Time_Measured_2_PST', 'staff_gauge_ht_ft', 'data_downloaded', 'logger_serial', 'time_logger_pulled_UTC_time_PST', 'time_logger_re_deployed_UTC_t_PST', 'battery', 'additional_notes', 'globalid', 'SHAPE']]\n",
    "\n",
    "# Rename columns\n",
    "sedfHydroStaffGageData.rename(columns = {'todays_date_PST':'Date', 'UTC_Time_Measured_4_PST':'Time of Measurement 1 (PST)', 'observers':'Observers', 'observers_other':'Other Observers', 'creek_gauge_ft':'Water Level, Arrival (ft)', 'UTC_Time_Measured_2_PST':'Time of Measurement 2 (PST)', 'staff_gauge_ht_ft':'Water Level, Departure (ft)', 'data_downloaded':'Downloaded Data', 'logger_serial':'Logger Serial#', 'time_logger_pulled_UTC_time_PST':'Time Logger Pulled (PST)', 'time_logger_re_deployed_UTC_t_PST':'Time Logger Re-deployed (PST)', 'battery':'Battery', 'additional_notes':'Notes', 'globalid':'GlobalID', 'SHAPE':'SHAPE'}, inplace= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Subset data for piezometer Piez P1 East at Wilson Dairy, Nisqually NWR\n",
    "\n",
    "## Select data based on 2 conditions: measurement type = piezometer and location = piezometer_1_east\n",
    "# Create filter\n",
    "PiezP1_filter = (sedfHydroAllData['Measurement_Type'] == \"piezometers\") & (sedfHydroAllData['Location__logger'] == \"piezometer_1_east\")\n",
    "# Copy HydroAllData to new dataframe\n",
    "sedfHydroPiezP1EastData = sedfHydroAllData.copy()\n",
    "# Create new column for Height of water above HOBO\n",
    "sedfHydroPiezP1EastData['Height of water above HOBO (Ft; length of stick = 6.20)'] = ''\n",
    "# Calculate Height of water above HOBO (length of stick = 6.20')\n",
    "lengthofstickP1 = 6.2\n",
    "\n",
    "sedfHydroPiezP1EastData.loc[PiezP1_filter, ['Height of water above HOBO (Ft; length of stick = 6.20)']] = lengthofstickP1 - sedfHydroPiezP1EastData['depth_to_water_level_inside_wel']\n",
    "\n",
    "# Select columns and reset in desired order\n",
    "sedfHydroPiezP1EastData = sedfHydroPiezP1EastData.loc[PiezP1_filter, ['todays_date_PST', 'UTC_Time_Measured_1_PST', 'observers', 'observers_other', 'depth_to_water_level_inside_wel', 'Height of water above HOBO (Ft; length of stick = 6.20)', 'depth_to_water_outside_well_ft', 'depth_to_ground_level_inside_we', 'depth_to_ground_outside_well_ft', 'data_downloaded', 'logger_serial', 'time_logger_pulled_UTC_time_PST', 'time_logger_re_deployed_UTC_t_PST', 'battery', 'additional_notes', 'globalid', 'SHAPE']]\n",
    "\n",
    "# Rename columns\n",
    "sedfHydroPiezP1EastData.rename(columns = {'todays_date_PST':'Date', 'UTC_Time_Measured_1_PST':'Time of Measurement (PST)', 'observers':'Observers', 'observers_other':'Other Observers', 'depth_to_water_level_inside_wel':'Depth to Water Level Inside Well (Ft)', 'depth_to_water_outside_well_ft':'Depth to Water Outside Well (Ft)', 'depth_to_ground_level_inside_we':'Depth to Ground Level Inside Well (Ft)', 'depth_to_ground_outside_well_ft':'Depth to Ground Outside Well (Ft)', 'data_downloaded':'Downloaded Data', 'logger_serial':'Logger Serial#', 'time_logger_pulled_UTC_time_PST':'Time Logger Pulled (PST)', 'time_logger_re_deployed_UTC_t_PST':'Time Logger Re-deployed (PST)', 'battery':'Battery', 'additional_notes':'Notes', 'globalid':'GlobalID', 'SHAPE':'SHAPE'}, inplace= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Subset data for piezometer Piez P2 Central at Wilson Dairy, Nisqually NWR\n",
    "\n",
    "## Select data based on 2 conditions: measurement type = piezometer and location = piezometer_2_central\n",
    "# Create filter\n",
    "PiezP2_filter = (sedfHydroAllData['Measurement_Type'] == \"piezometers\") & (sedfHydroAllData['Location__logger'] == \"piezometer_2_central\")\n",
    "# Copy HydroAllData to new dataframe\n",
    "sedfHydroPiezP2CentralData = sedfHydroAllData.copy()\n",
    "# Create new column for Height of water above HOBO\n",
    "sedfHydroPiezP2CentralData['Height of water above HOBO (Ft; length of stick = 6.20)'] = ''\n",
    "# Calculate Height of water above HOBO (length of stick = 6.20')\n",
    "lengthofstickP2 = 6.2\n",
    "\n",
    "sedfHydroPiezP2CentralData.loc[PiezP2_filter, ['Height of water above HOBO (Ft; length of stick = 6.20)']] = lengthofstickP2 - sedfHydroPiezP2CentralData['depth_to_water_level_inside_wel']\n",
    "\n",
    "# Select columns and reset in desired order\n",
    "sedfHydroPiezP2CentralData = sedfHydroPiezP2CentralData.loc[PiezP2_filter, ['todays_date_PST', 'UTC_Time_Measured_1_PST', 'observers', 'observers_other', 'depth_to_water_level_inside_wel', 'Height of water above HOBO (Ft; length of stick = 6.20)', 'depth_to_water_outside_well_ft', 'depth_to_ground_level_inside_we', 'depth_to_ground_outside_well_ft', 'data_downloaded', 'logger_serial', 'time_logger_pulled_UTC_time_PST', 'time_logger_re_deployed_UTC_t_PST', 'battery', 'additional_notes', 'globalid', 'SHAPE']]\n",
    "\n",
    "# Rename columns\n",
    "sedfHydroPiezP2CentralData.rename(columns = {'todays_date_PST':'Date', 'UTC_Time_Measured_1_PST':'Time of Measurement (PST)', 'observers':'Observers', 'observers_other':'Other Observers', 'depth_to_water_level_inside_wel':'Depth to Water Level Inside Well (Ft)', 'depth_to_water_outside_well_ft':'Depth to Water Outside Well (Ft)', 'depth_to_ground_level_inside_we':'Depth to Ground Level Inside Well (Ft)', 'depth_to_ground_outside_well_ft':'Depth to Ground Outside Well (Ft)', 'data_downloaded':'Downloaded Data', 'logger_serial':'Logger Serial#', 'time_logger_pulled_UTC_time_PST':'Time Logger Pulled (PST)', 'time_logger_re_deployed_UTC_t_PST':'Time Logger Re-deployed (PST)', 'battery':'Battery', 'additional_notes':'Notes', 'globalid':'GlobalID', 'SHAPE':'SHAPE'}, inplace= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Subset data for piezometer Piez P3 West at Wilson Dairy, Nisqually NWR\n",
    "\n",
    "## Select data based on 2 conditions: measurement type = piezometer and location = piezometer_3_west\n",
    "# Create filter\n",
    "PiezP3_filter = (sedfHydroAllData['Measurement_Type'] == \"piezometers\") & (sedfHydroAllData['Location__logger'] == \"piezometer_3_west\")\n",
    "# Copy HydroAllData to new dataframe\n",
    "sedfHydroPiezP3WestData = sedfHydroAllData.copy()\n",
    "# Create new column for Height of water above HOBO\n",
    "sedfHydroPiezP3WestData['Height of water above HOBO (Ft; length of stick = 5.65)'] = ''\n",
    "# Calculate Height of water above HOBO (length of stick = 5.65')\n",
    "lengthofstickP3 = 5.65\n",
    "\n",
    "sedfHydroPiezP3WestData.loc[PiezP3_filter, ['Height of water above HOBO (Ft; length of stick = 5.65)']] = lengthofstickP3 - sedfHydroPiezP3WestData['depth_to_water_level_inside_wel']\n",
    "\n",
    "# Select columns and reset in desired order\n",
    "sedfHydroPiezP3WestData = sedfHydroPiezP3WestData.loc[PiezP3_filter, ['todays_date_PST', 'UTC_Time_Measured_1_PST', 'observers', 'observers_other', 'depth_to_water_level_inside_wel', 'Height of water above HOBO (Ft; length of stick = 5.65)', 'depth_to_water_outside_well_ft', 'depth_to_ground_level_inside_we', 'depth_to_ground_outside_well_ft', 'data_downloaded', 'logger_serial', 'time_logger_pulled_UTC_time_PST', 'time_logger_re_deployed_UTC_t_PST', 'battery', 'additional_notes', 'globalid', 'SHAPE']]\n",
    "\n",
    "# Rename columns\n",
    "sedfHydroPiezP3WestData.rename(columns = {'todays_date_PST':'Date', 'UTC_Time_Measured_1_PST':'Time of Measurement (PST)', 'observers':'Observers', 'observers_other':'Other Observers', 'depth_to_water_level_inside_wel':'Depth to Water Level Inside Well (Ft)', 'depth_to_water_outside_well_ft':'Depth to Water Outside Well (Ft)', 'depth_to_ground_level_inside_we':'Depth to Ground Level Inside Well (Ft)', 'depth_to_ground_outside_well_ft':'Depth to Ground Outside Well (Ft)', 'data_downloaded':'Downloaded Data', 'logger_serial':'Logger Serial#', 'time_logger_pulled_UTC_time_PST':'Time Logger Pulled (PST)', 'time_logger_re_deployed_UTC_t_PST':'Time Logger Re-deployed (PST)', 'battery':'Battery', 'additional_notes':'Notes', 'globalid':'GlobalID', 'SHAPE':'SHAPE'}, inplace= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Subset data for culverts\n",
    "\n",
    "## Select data based on 1 condition: measurement type = culverts\n",
    "sedfHydroCulvertsData = sedfHydroAllData.loc[(sedfHydroAllData['Measurement_Type'] == \"culverts\"), ['Location_culvert', 'todays_date_PST', 'UTC_Time_Measured_3_PST', 'observers', 'observers_other', 'Depth_to_H20_fr0m_top_culvrt_ft', 'additional_notes', 'globalid', 'SHAPE', 'todays_date']]\n",
    "\n",
    "# Define sort order\n",
    "sedfHydroCulvertsData = sedfHydroCulvertsData.sort_values(by=['Location_culvert', 'todays_date'])\n",
    "\n",
    "# Drop todays_date\n",
    "del sedfHydroCulvertsData['todays_date']\n",
    "\n",
    "# Rename columns\n",
    "sedfHydroCulvertsData.rename(columns = {'Location_culvert':'Culvert', 'todays_date_PST':'Date', 'UTC_Time_Measured_3_PST':'Time of Measurement (PST)', 'observers':'Observers', 'observers_other':'Other Observers', 'Depth_to_H20_fr0m_top_culvrt_ft':'Depth to Water Level from Culvert Top (Ft)', 'additional_notes':'Notes', 'globalid':'GlobalID', 'SHAPE':'SHAPE'}, inplace= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Calculate water elevation data at staff gage (NAVD88 and Gage Datum)\n",
    "\n",
    "## Get unique combinations of staff gage reading date and water level\n",
    "# Copy sedfHydroStaffGageData\n",
    "uniqueStaffGage = sedfHydroStaffGageData.copy()\n",
    "\n",
    "# Fill NaN with 0\n",
    "uniqueStaffGage[['Water Level, Arrival (ft)', 'Water Level, Departure (ft)']] = uniqueStaffGage[['Water Level, Arrival (ft)', 'Water Level, Departure (ft)']].fillna(0)\n",
    "# Data structured such that Water Level Arrival and Departure mutually exclusive so summing them give the single water level value\n",
    "uniqueStaffGage['Water Level'] = uniqueStaffGage['Water Level, Arrival (ft)'] + uniqueStaffGage['Water Level, Departure (ft)'] \n",
    "\n",
    "# Convert Date to Python date field for sorting\n",
    "uniqueStaffGage['Date'] = pd.to_datetime(uniqueStaffGage['Date'], format = '%m/%d/%Y')\n",
    "\n",
    "# Subset to Date and Water Level fields\n",
    "uniqueStaffGage = uniqueStaffGage[['Date', 'Water Level']]\n",
    "\n",
    "# Group by to select unique combinations of Date and Water Level\n",
    "uniqueStaffGage = uniqueStaffGage.groupby(['Date', 'Water Level']).size().reset_index().rename(columns={0:'count'})\n",
    "\n",
    "### Calculate Water Elevation Data (NAVD88 and Gage Datum)\n",
    "uniqueStaffGage['Staff (NAVD88)'] = locations.loc[1, 'Elevation of M.P. (Ft)'] + uniqueStaffGage['Water Level']\n",
    "uniqueStaffGage['Staff (Gage Datum)'] = uniqueStaffGage['Staff (NAVD88)'] - locations.loc[1, 'Elevation of M.P. (Ft)'] \n",
    "\n",
    "# Sort by date\n",
    "uniqueStaffGage = uniqueStaffGage.sort_values(by=['Date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Calculate water elevation data at piezometers (NAVD88 and Gage Datum)\n",
    "# PiezP1East\n",
    "uniquePiezP1East = sedfHydroPiezP1EastData.copy()\n",
    "uniquePiezP1East['Water Inside P1 (NAVD88)'] = locations.loc[2, 'Elevation of M.P. (Ft)'] - uniquePiezP1East['Depth to Water Level Inside Well (Ft)']\n",
    "uniquePiezP1East['Date'] = pd.to_datetime(uniquePiezP1East['Date'], format = '%m/%d/%Y')\n",
    "uniquePiezP1East = uniquePiezP1East[['Date', 'Water Inside P1 (NAVD88)']]\n",
    "uniquePiezP1East.dropna(subset=['Water Inside P1 (NAVD88)'], inplace= True)\n",
    "uniquePiezP1East = uniquePiezP1East.sort_values(by=['Date'])\n",
    "uniquePiezP1East['Water Inside P1 (Gage Datum)'] = uniquePiezP1East['Water Inside P1 (NAVD88)'] - locations.loc[1, 'Elevation of M.P. (Ft)'] \n",
    "# PiezP2Central\n",
    "uniquePiezP2Central = sedfHydroPiezP2CentralData.copy()\n",
    "uniquePiezP2Central['Water Inside P2 (NAVD88)'] = locations.loc[3, 'Elevation of M.P. (Ft)'] - uniquePiezP2Central['Depth to Water Level Inside Well (Ft)']\n",
    "uniquePiezP2Central['Date'] = pd.to_datetime(uniquePiezP2Central['Date'], format = '%m/%d/%Y')\n",
    "uniquePiezP2Central = uniquePiezP2Central[['Date', 'Water Inside P2 (NAVD88)']]\n",
    "uniquePiezP2Central.dropna(subset=['Water Inside P2 (NAVD88)'], inplace= True)\n",
    "uniquePiezP2Central = uniquePiezP2Central.sort_values(by=['Date'])\n",
    "uniquePiezP2Central['Water Inside P2 (Gage Datum)'] = uniquePiezP2Central['Water Inside P2 (NAVD88)'] - locations.loc[1, 'Elevation of M.P. (Ft)'] \n",
    "# PiezP3West\n",
    "uniquePiezP3West = sedfHydroPiezP3WestData.copy()\n",
    "uniquePiezP3West['Water Inside P3 (NAVD88)'] = locations.loc[4, 'Elevation of M.P. (Ft)'] - uniquePiezP3West['Depth to Water Level Inside Well (Ft)']\n",
    "uniquePiezP3West['Date'] = pd.to_datetime(uniquePiezP3West['Date'], format = '%m/%d/%Y')\n",
    "uniquePiezP3West = uniquePiezP3West[['Date', 'Water Inside P3 (NAVD88)']]\n",
    "uniquePiezP3West.dropna(subset=['Water Inside P3 (NAVD88)'], inplace= True)\n",
    "uniquePiezP3West = uniquePiezP3West.sort_values(by=['Date'])\n",
    "uniquePiezP3West['Water Inside P3 (Gage Datum)'] = uniquePiezP3West['Water Inside P3 (NAVD88)'] - locations.loc[1, 'Elevation of M.P. (Ft)'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Calculate water elevation data at culverts (NAVD88 and Gage Datum)\n",
    "uniqueCulverts = sedfHydroCulvertsData.copy()\n",
    "culvert1_filter = sedfHydroCulvertsData['Culvert'] == \"culvert_1_east\"\n",
    "culvert2_filter = sedfHydroCulvertsData['Culvert'] == \"culvert_2_middle\"\n",
    "culvert3_filter = sedfHydroCulvertsData['Culvert'] == \"culvert_3_west\"\n",
    "\n",
    "uniqueCulverts.loc[culvert1_filter, ['Culvert 1 (NAVD88)']] = locations.loc[5, 'Elevation of M.P. (Ft)'] - uniqueCulverts['Depth to Water Level from Culvert Top (Ft)']\n",
    "uniqueCulverts.loc[culvert2_filter, ['Culvert 2 (NAVD88)']] = locations.loc[6, 'Elevation of M.P. (Ft)'] - uniqueCulverts['Depth to Water Level from Culvert Top (Ft)']\n",
    "uniqueCulverts.loc[culvert3_filter, ['Culvert 3 (NAVD88)']] = locations.loc[7, 'Elevation of M.P. (Ft)'] - uniqueCulverts['Depth to Water Level from Culvert Top (Ft)']\n",
    "\n",
    "uniqueCulverts['Culvert 1 (Gage Datum)'] = uniqueCulverts['Culvert 1 (NAVD88)'] - locations.loc[1, 'Elevation of M.P. (Ft)'] \n",
    "uniqueCulverts['Culvert 2 (Gage Datum)'] = uniqueCulverts['Culvert 2 (NAVD88)'] - locations.loc[1, 'Elevation of M.P. (Ft)'] \n",
    "uniqueCulverts['Culvert 3 (Gage Datum)'] = uniqueCulverts['Culvert 3 (NAVD88)'] - locations.loc[1, 'Elevation of M.P. (Ft)'] \n",
    "\n",
    "uniqueCulverts['Date'] = pd.to_datetime(uniqueCulverts['Date'], format = '%m/%d/%Y')\n",
    "\n",
    "uniqueCulverts = uniqueCulverts[['Date', 'Culvert 1 (NAVD88)', 'Culvert 2 (NAVD88)', 'Culvert 3 (NAVD88)', 'Culvert 1 (Gage Datum)', 'Culvert 2 (Gage Datum)', 'Culvert 3 (Gage Datum)']]\n",
    "\n",
    "uniqueCulverts = uniqueCulverts.sort_values(by=['Date'])\n",
    "\n",
    "culvert1_waterElev = uniqueCulverts[['Date', 'Culvert 1 (NAVD88)', 'Culvert 1 (Gage Datum)']].copy()\n",
    "culvert1_waterElev.dropna(subset=['Culvert 1 (NAVD88)', 'Culvert 1 (Gage Datum)'], inplace= True)\n",
    "\n",
    "culvert2_waterElev = uniqueCulverts[['Date', 'Culvert 2 (NAVD88)', 'Culvert 2 (Gage Datum)']].copy()\n",
    "culvert2_waterElev.dropna(subset=['Culvert 2 (NAVD88)', 'Culvert 2 (Gage Datum)'], inplace= True)\n",
    "\n",
    "culvert3_waterElev = uniqueCulverts[['Date', 'Culvert 3 (NAVD88)', 'Culvert 3 (Gage Datum)']].copy()\n",
    "culvert3_waterElev.dropna(subset=['Culvert 3 (NAVD88)', 'Culvert 3 (Gage Datum)'], inplace= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Combine data\n",
    "combine = pd.merge(uniqueStaffGage, uniquePiezP1East, how=\"outer\", left_on=\"Date\", right_on=\"Date\")\n",
    "del combine['count']\n",
    "combine = pd.merge(combine, uniquePiezP2Central, how=\"outer\", left_on=\"Date\", right_on=\"Date\")\n",
    "combine = pd.merge(combine, uniquePiezP3West, how=\"outer\", left_on=\"Date\", right_on=\"Date\")\n",
    "combine = pd.merge(combine, culvert1_waterElev, how=\"outer\", left_on=\"Date\", right_on=\"Date\")\n",
    "combine = pd.merge(combine, culvert2_waterElev, how=\"outer\", left_on=\"Date\", right_on=\"Date\")\n",
    "combine = pd.merge(combine, culvert3_waterElev, how=\"outer\", left_on=\"Date\", right_on=\"Date\")\n",
    "\n",
    "waterElev_NAVD88 = combine[['Date', 'Staff (NAVD88)', 'Water Inside P1 (NAVD88)', 'Water Inside P2 (NAVD88)', 'Water Inside P3 (NAVD88)', 'Culvert 1 (NAVD88)', 'Culvert 2 (NAVD88)', 'Culvert 3 (NAVD88)']].copy()\n",
    "waterElev_NAVD88['Date'] = waterElev_NAVD88['Date'].dt.strftime('%m/%d/%Y')\n",
    "\n",
    "waterElev_GageDatum = combine[['Date', 'Staff (Gage Datum)', 'Water Inside P1 (Gage Datum)', 'Water Inside P2 (Gage Datum)', 'Water Inside P3 (Gage Datum)', 'Culvert 1 (Gage Datum)', 'Culvert 2 (Gage Datum)', 'Culvert 3 (Gage Datum)']].copy()\n",
    "waterElev_GageDatum['Date'] = waterElev_GageDatum['Date'].dt.strftime('%m/%d/%Y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "### Create export paths\n",
    "writer = pd.ExcelWriter(os.path.join(out_workspace,(timestamp + '_WilsonDairyHydro.xlsx')))\n",
    "metadata.to_excel(writer, 'Metadata')\n",
    "sedfHydroStaffGageData.to_excel(writer, 'Staff Gage')\n",
    "sedfHydroPiezP1EastData.to_excel(writer, 'Piez P1 East')\n",
    "sedfHydroPiezP2CentralData.to_excel(writer, 'Piez P2 Central')\n",
    "sedfHydroPiezP3WestData.to_excel(writer, 'Piez P3 West')\n",
    "sedfHydroCulvertsData.to_excel(writer, 'Culverts')\n",
    "locations.to_excel(writer, 'Locations & MP Elevations')\n",
    "waterElev_NAVD88.to_excel(writer, 'Water Elevation, NAVD88')\n",
    "waterElev_GageDatum.to_excel(writer, 'Water Elevation, Gage Datum')\n",
    "sedfHydroAllDataArchive.to_excel(writer, (timestamp + \" AGOL Data\"))\n",
    "writer.save()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
