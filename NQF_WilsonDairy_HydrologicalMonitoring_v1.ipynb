{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "### NQF_WilsonDairy_HydrologicalMonitoring_v1.py\n",
    "### Version: 6/7/2021\n",
    "### Author: Khem So, khem_so@fws.gov, (503) 231-6839\n",
    "### Abstract: This Python 3 script pulls data from the Wilson Dairy Hydrological Data V2 ArcGIS Online feature service (collected via Survey123) and summarizes the data to match an Excel template."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import arcpy\n",
    "import pandas as pd\n",
    "from arcgis import GIS\n",
    "import time, os, fnmatch, shutil\n",
    "import openpyxl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "### ArcGIS Online stores date-time information in UTC by default. This function uses the pytz package to convert time zones and can be used to convert from UTC (\"UTC\") to localized time. For example, localized \"US/Pacific\" is either Pacific Standard Time UTC-8 or Pacific Daylight Time UTC-7 depending upon time of year.\n",
    "from datetime import datetime\n",
    "from pytz import timezone\n",
    "def change_timezone_of_field(df, source_date_time_field, new_date_time_field_suffix, source_timezone, new_timezone):\n",
    "    \"\"\"Returns the values in *source_date_time_field* with its timezone converted to a new timezone within a new field *new_date_time_field*\n",
    "    : param df: The name of the spatially enabled or pandas DataFrame containing datetime fields\n",
    "    : param source_date_time_field: The name of the datetime field whose timezone is to be changed\n",
    "    : param new_date_time_field_suffix: Suffix appended to the end of the name of the source datetime field. This is used to create the new date time field name.\n",
    "    : param source_timezone: The name of the source timezone\n",
    "    : param new_timezone: The name of the converted timezone. For possible values, see https://gist.github.com/heyalexej/8bf688fd67d7199be4a1682b3eec7568\n",
    "    \"\"\"\n",
    "    # Define the source timezone in the source_date_time_field\n",
    "    df[source_date_time_field] = df[source_date_time_field].dt.tz_localize(source_timezone)\n",
    "    # Define the name of the new date time field\n",
    "    new_date_time_field = source_date_time_field + new_date_time_field_suffix\n",
    "    # Convert the datetime in the source_date_time_field to the new timezone in a new field called new_date_time_field\n",
    "    df[new_date_time_field] = df[source_date_time_field].dt.tz_convert(new_timezone)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Alternative to change_timezone_of_field function. This function assumes that a source datetime field is UTC and then will calculate a UTC offset (number of hours) on a new datetime field.\n",
    "from datetime import datetime, timedelta, timezone\n",
    "def utc_offset_timezone_of_field(df, source_date_time_field, new_date_time_field_suffix, new_timezone_utc_offset):\n",
    "    \"\"\"Returns the values in *source_date_time_field* with its timezone converted to a new timezone within a new field *new_date_time_field*\n",
    "    : param df: The name of the spatially enabled or pandas DataFrame containing datetime fields\n",
    "    : param source_date_time_field: The name of the datetime field whose timezone is to be changed\n",
    "    : param new_date_time_field_suffix: Suffix appended to the end of the name of the source datetime field. This is used to create the new date time field name.\n",
    "    : param new_timezone_utc_offset: Number of hours offset from UTC. For example Pacific Standard Time is -8.\n",
    "    \"\"\"\n",
    "    # Define the UTC offset\n",
    "    offset_tz = timezone(timedelta(hours=new_timezone_utc_offset))\n",
    "    offset_td = timedelta(hours=new_timezone_utc_offset)\n",
    "    # Define the name of the new date time field\n",
    "    new_date_time_field = source_date_time_field + new_date_time_field_suffix\n",
    "    # Create a temporary offset field\n",
    "    df['Offset_temp'] = offset_td\n",
    "    # Calculate the new_date_time_field based arithmetic on the source_date_time_field\n",
    "    df[new_date_time_field] = df[source_date_time_field] + df['Offset_temp']\n",
    "    # Define timezone for new_date_time_field\n",
    "    df[new_date_time_field] = df[new_date_time_field].dt.tz_localize(offset_tz)\n",
    "    # Define the source timezone in the source_date_time_field\n",
    "    df[source_date_time_field] = df[source_date_time_field].dt.tz_localize('UTC')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Allow authentication via login to U.S. Fish & Wildlife Service ArcGIS Online account via ArcGIS Pro\n",
    "gis = GIS(\"pro\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Enter path for local file saving\n",
    "# uncomment next line to use ArcGIS interface, otherwise hard coding out_workspace\n",
    "# out_workspace = arcpy.GetParameterAsText(0)\n",
    "out_workspace = \"C:/Users/kso/Desktop/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Create timestamp for file naming\n",
    "t = time.localtime()\n",
    "timestamp = time.strftime('%Y-%m-%d_%H%M', t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Paths to ArcGIS Online data\n",
    "# To populate Service ItemId, go to Feature Service webpage and in bottom right corner, click on the View link.\n",
    "# Current Feature Service webpage: https://fws.maps.arcgis.com/home/item.html?id=c6b4f8f33b804dea8c2232c3d7786e9f\n",
    "ServiceItemID = gis.content.get(\"c6b4f8f33b804dea8c2232c3d7786e9f\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "### There are separate methods for pulling spatial versus non-spatial data into Python. Spatial layers will become Spatially Enabled DataFrame objects. \n",
    "## Define variables pointing to spatial layers\n",
    "WilsonHydroMonitoringLyr = ServiceItemID.layers[0]\n",
    "## Create Spatially Enabled DataFrame objects\n",
    "sedfHydroAllData = pd.DataFrame.spatial.from_layer(WilsonHydroMonitoringLyr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['objectid',\n",
       " 'globalid',\n",
       " 'CreationDate',\n",
       " 'Creator',\n",
       " 'EditDate',\n",
       " 'Editor',\n",
       " 'observers',\n",
       " 'observers_other',\n",
       " 'todays_date',\n",
       " 'Measurement_Type',\n",
       " 'what_are_you_measuring_other',\n",
       " 'creek_gauge_ft',\n",
       " 'UTC_Time_Measured_4',\n",
       " 'Location__logger',\n",
       " 'UTC_Time_Measured_1',\n",
       " 'depth_to_water_level_inside_wel',\n",
       " 'depth_to_water_outside_well_ft',\n",
       " 'depth_to_ground_level_inside_we',\n",
       " 'depth_to_ground_outside_well_ft',\n",
       " 'UTC_Time_Measured_2',\n",
       " 'staff_gauge_ht_ft',\n",
       " 'data_downloaded',\n",
       " 'logger_serial',\n",
       " 'time_logger_pulled_UTC_time',\n",
       " 'time_logger_re_deployed_UTC_t',\n",
       " 'battery',\n",
       " 'Location_culvert',\n",
       " 'Depth_to_H20_fr0m_top_culvrt_ft',\n",
       " 'UTC_Time_Measured_3',\n",
       " 'additional_notes',\n",
       " 'Measurement_Type_other',\n",
       " 'Location__logger_other',\n",
       " 'SHAPE']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(sedfHydroAllData.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Create Metadata sheet\n",
    "# Initialize blank metadata dataframe and add columns\n",
    "metadata = pd.DataFrame(columns = ['Sheet', 'Description'])\n",
    "\n",
    "# Add records to metadata dataframe using the .loc function\n",
    "metadata.loc[0] = [\"Staff Gage\",\"Nisqually NWR Dempsey Creek Staff Gage at Wilson Dairy\"]\n",
    "metadata.loc[1] = [\"Piez P1 East\",\"Nisqually NWR Wilson Dairy - Piezometer P1 (East). Tapedown measurements are made from the measuring point marked on the top of the piezometer. Piezometer 1 (East) Stick-up = 2.57\"]\n",
    "metadata.loc[2] = [\"Piez P2 Central\",\"Nisqually NWR Wilson Dairy - Piezometer P2 (Central). Tapedown measurements are made from the measuring point marked on the top of the piezometer. Piezometer 2 (Central) Stick-up = 2.81\"]\n",
    "metadata.loc[3] = [\"Piez P3 West\",\"Nisqually NWR Wilson Dairy - Piezometer P3 (West). Tapedown measurements are made from the measuring point marked on the top of the piezometer. Piezometer 3 (West) Stick-up = 2.87\"]\n",
    "metadata.loc[4] = [\"Culverts\",\"Nisqually NWR Dephi Road Culverts at Wilson Dairy. Measurements are taken from a measuring point marked on the top of each culvert pipe. Culvert 1 (East) Diameter = 4.97. Culvert 2 (Central) Diameter = 6.0. Culvert 3 (West) Diameter = 6.0. \"]\n",
    "metadata.loc[5] = [\"Locations & MP Elevations\",\"Nisqually NWR Staff Gage, Piezometer, and Culvert Locations and Measuring Point Elevations at Wilson Dairy. Location Datum: NAD83(2011); Vertical Datum: NAVD88\"]\n",
    "metadata.loc[6] = [\"Water Elevation Data, NAVD88\",\"Nisqually NWR Wilson Dairy - Water Elevation Data (NAVD88)\"]\n",
    "metadata.loc[7] = [\"WL Data, Gage Datum\",\"Nisqually NWR Wilson Dairy - Water Elevation Data (Gage Datum). 0 on Staff Gage = 138.899\"]\n",
    "metadata.loc[8] = [timestamp + \" AGOL Data\",\"ArcGIS Online Data Download\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## Alternative 1: Use change_timezone_of_field function to convert all datetime fields in dataframe from UTC to Pacific within new field with _Pacific suffix\n",
    "# for col in sedfHydroAllData.columns:\n",
    "#     if sedfHydroAllData[col].dtype == 'datetime64[ns]':\n",
    "#         change_timezone_of_field(sedfHydroAllData, col, \"_Pacific\", \"UTC\", \"US/Pacific\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Alternative 2: Use utc_offset_timezone_of_field function to convert all datetime fields in dataframe from UTC to PST within new field with _PST suffix\n",
    "for col in sedfHydroAllData.columns:\n",
    "    if sedfHydroAllData[col].dtype == 'datetime64[ns]':\n",
    "        utc_offset_timezone_of_field(sedfHydroAllData, col, '_PST', -8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "objectid                                                 int64\n",
       "globalid                                                object\n",
       "CreationDate                               datetime64[ns, UTC]\n",
       "Creator                                                 object\n",
       "EditDate                                   datetime64[ns, UTC]\n",
       "Editor                                                  object\n",
       "observers                                               object\n",
       "observers_other                                         object\n",
       "todays_date                                datetime64[ns, UTC]\n",
       "Measurement_Type                                        object\n",
       "what_are_you_measuring_other                            object\n",
       "creek_gauge_ft                                         float64\n",
       "UTC_Time_Measured_4                        datetime64[ns, UTC]\n",
       "Location__logger                                        object\n",
       "UTC_Time_Measured_1                        datetime64[ns, UTC]\n",
       "depth_to_water_level_inside_wel                        float64\n",
       "depth_to_water_outside_well_ft                         float64\n",
       "depth_to_ground_level_inside_we                        float64\n",
       "depth_to_ground_outside_well_ft                        float64\n",
       "UTC_Time_Measured_2                        datetime64[ns, UTC]\n",
       "staff_gauge_ht_ft                                      float64\n",
       "data_downloaded                                         object\n",
       "logger_serial                                           object\n",
       "time_logger_pulled_UTC_time                datetime64[ns, UTC]\n",
       "time_logger_re_deployed_UTC_t              datetime64[ns, UTC]\n",
       "battery                                                 object\n",
       "Location_culvert                                        object\n",
       "Depth_to_H20_fr0m_top_culvrt_ft                        float64\n",
       "UTC_Time_Measured_3                        datetime64[ns, UTC]\n",
       "additional_notes                                        object\n",
       "Measurement_Type_other                                  object\n",
       "Location__logger_other                                  object\n",
       "SHAPE                                                 geometry\n",
       "Offset_temp                                    timedelta64[ns]\n",
       "CreationDate_PST                     datetime64[ns, UTC-08:00]\n",
       "EditDate_PST                         datetime64[ns, UTC-08:00]\n",
       "todays_date_PST                      datetime64[ns, UTC-08:00]\n",
       "UTC_Time_Measured_4_PST              datetime64[ns, UTC-08:00]\n",
       "UTC_Time_Measured_1_PST              datetime64[ns, UTC-08:00]\n",
       "UTC_Time_Measured_2_PST              datetime64[ns, UTC-08:00]\n",
       "time_logger_pulled_UTC_time_PST      datetime64[ns, UTC-08:00]\n",
       "time_logger_re_deployed_UTC_t_PST    datetime64[ns, UTC-08:00]\n",
       "UTC_Time_Measured_3_PST              datetime64[ns, UTC-08:00]\n",
       "dtype: object"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check data types\n",
    "sedfHydroAllData.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CreationDate</th>\n",
       "      <th>EditDate</th>\n",
       "      <th>todays_date</th>\n",
       "      <th>UTC_Time_Measured_4</th>\n",
       "      <th>UTC_Time_Measured_1</th>\n",
       "      <th>UTC_Time_Measured_2</th>\n",
       "      <th>time_logger_pulled_UTC_time</th>\n",
       "      <th>time_logger_re_deployed_UTC_t</th>\n",
       "      <th>UTC_Time_Measured_3</th>\n",
       "      <th>CreationDate_PST</th>\n",
       "      <th>EditDate_PST</th>\n",
       "      <th>todays_date_PST</th>\n",
       "      <th>UTC_Time_Measured_4_PST</th>\n",
       "      <th>UTC_Time_Measured_1_PST</th>\n",
       "      <th>UTC_Time_Measured_2_PST</th>\n",
       "      <th>time_logger_pulled_UTC_time_PST</th>\n",
       "      <th>time_logger_re_deployed_UTC_t_PST</th>\n",
       "      <th>UTC_Time_Measured_3_PST</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-02-19 01:27:35.359999895+00:00</td>\n",
       "      <td>2020-03-04 20:01:31.436000109+00:00</td>\n",
       "      <td>2020-02-18 20:00:00+00:00</td>\n",
       "      <td>2020-02-18 20:30:00+00:00</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>2020-02-18 17:27:35.359999895-08:00</td>\n",
       "      <td>2020-03-04 12:01:31.436000109-08:00</td>\n",
       "      <td>2020-02-18 12:00:00-08:00</td>\n",
       "      <td>2020-02-18 12:30:00-08:00</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-02-19 01:27:41.535000086+00:00</td>\n",
       "      <td>2020-02-19 01:27:41.535000086+00:00</td>\n",
       "      <td>2020-02-18 20:00:00+00:00</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>2020-02-18 20:34:09.976000071+00:00</td>\n",
       "      <td>2020-02-18 20:33:00+00:00</td>\n",
       "      <td>2020-02-18 20:38:00+00:00</td>\n",
       "      <td>NaT</td>\n",
       "      <td>2020-02-18 17:27:41.535000086-08:00</td>\n",
       "      <td>2020-02-18 17:27:41.535000086-08:00</td>\n",
       "      <td>2020-02-18 12:00:00-08:00</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>2020-02-18 12:34:09.976000071-08:00</td>\n",
       "      <td>2020-02-18 12:33:00-08:00</td>\n",
       "      <td>2020-02-18 12:38:00-08:00</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-02-19 01:27:44.867000103+00:00</td>\n",
       "      <td>2020-02-19 01:27:44.867000103+00:00</td>\n",
       "      <td>2020-02-18 20:00:00+00:00</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>2020-02-18 20:26:40.049999952+00:00</td>\n",
       "      <td>2020-02-18 20:27:00+00:00</td>\n",
       "      <td>NaT</td>\n",
       "      <td>2020-02-18 17:27:44.867000103-08:00</td>\n",
       "      <td>2020-02-18 17:27:44.867000103-08:00</td>\n",
       "      <td>2020-02-18 12:00:00-08:00</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>2020-02-18 12:26:40.049999952-08:00</td>\n",
       "      <td>2020-02-18 12:27:00-08:00</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-02-19 01:27:48.403000116+00:00</td>\n",
       "      <td>2020-02-19 01:27:48.403000116+00:00</td>\n",
       "      <td>2020-02-18 20:00:00+00:00</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>2020-02-18 20:23:44.302999973+00:00</td>\n",
       "      <td>2020-02-18 20:24:00+00:00</td>\n",
       "      <td>NaT</td>\n",
       "      <td>2020-02-18 17:27:48.403000116-08:00</td>\n",
       "      <td>2020-02-18 17:27:48.403000116-08:00</td>\n",
       "      <td>2020-02-18 12:00:00-08:00</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>2020-02-18 12:23:44.302999973-08:00</td>\n",
       "      <td>2020-02-18 12:24:00-08:00</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-02-19 01:27:55.072999954+00:00</td>\n",
       "      <td>2020-02-19 05:24:42.161000013+00:00</td>\n",
       "      <td>2020-02-18 20:00:00+00:00</td>\n",
       "      <td>NaT</td>\n",
       "      <td>2020-02-18 20:00:34.260999918+00:00</td>\n",
       "      <td>NaT</td>\n",
       "      <td>2020-02-18 20:03:00+00:00</td>\n",
       "      <td>2020-02-18 20:11:21.598999977+00:00</td>\n",
       "      <td>NaT</td>\n",
       "      <td>2020-02-18 17:27:55.072999954-08:00</td>\n",
       "      <td>2020-02-18 21:24:42.161000013-08:00</td>\n",
       "      <td>2020-02-18 12:00:00-08:00</td>\n",
       "      <td>NaT</td>\n",
       "      <td>2020-02-18 12:00:34.260999918-08:00</td>\n",
       "      <td>NaT</td>\n",
       "      <td>2020-02-18 12:03:00-08:00</td>\n",
       "      <td>2020-02-18 12:11:21.598999977-08:00</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>210</th>\n",
       "      <td>2021-06-03 13:24:29.697000027+00:00</td>\n",
       "      <td>2021-06-03 13:24:29.697000027+00:00</td>\n",
       "      <td>2021-05-17 23:58:09.528000115+00:00</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>2021-05-17 23:58:20.746999979+00:00</td>\n",
       "      <td>2021-06-03 05:24:29.697000027-08:00</td>\n",
       "      <td>2021-06-03 05:24:29.697000027-08:00</td>\n",
       "      <td>2021-05-17 15:58:09.528000115-08:00</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>2021-05-17 15:58:20.746999979-08:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>211</th>\n",
       "      <td>2021-06-03 13:24:46.849999905+00:00</td>\n",
       "      <td>2021-06-03 13:24:46.849999905+00:00</td>\n",
       "      <td>2021-05-26 23:34:45.665999889+00:00</td>\n",
       "      <td>2021-05-26 23:35:00+00:00</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>2021-06-03 05:24:46.849999905-08:00</td>\n",
       "      <td>2021-06-03 05:24:46.849999905-08:00</td>\n",
       "      <td>2021-05-26 15:34:45.665999889-08:00</td>\n",
       "      <td>2021-05-26 15:35:00-08:00</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>212</th>\n",
       "      <td>2021-06-03 13:24:56.306999922+00:00</td>\n",
       "      <td>2021-06-03 13:24:56.306999922+00:00</td>\n",
       "      <td>2021-05-26 23:39:50.819999933+00:00</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>2021-05-26 23:40:00+00:00</td>\n",
       "      <td>2021-06-03 05:24:56.306999922-08:00</td>\n",
       "      <td>2021-06-03 05:24:56.306999922-08:00</td>\n",
       "      <td>2021-05-26 15:39:50.819999933-08:00</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>2021-05-26 15:40:00-08:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>213</th>\n",
       "      <td>2021-06-03 13:25:09.088999987+00:00</td>\n",
       "      <td>2021-06-03 13:25:09.088999987+00:00</td>\n",
       "      <td>2021-05-26 19:00:00+00:00</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>2021-05-26 23:43:00+00:00</td>\n",
       "      <td>2021-06-03 05:25:09.088999987-08:00</td>\n",
       "      <td>2021-06-03 05:25:09.088999987-08:00</td>\n",
       "      <td>2021-05-26 11:00:00-08:00</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>2021-05-26 15:43:00-08:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>214</th>\n",
       "      <td>2021-06-03 13:25:19.072000027+00:00</td>\n",
       "      <td>2021-06-03 13:25:19.072000027+00:00</td>\n",
       "      <td>2021-05-26 23:52:20.006000042+00:00</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>2021-05-26 23:50:00+00:00</td>\n",
       "      <td>2021-06-03 05:25:19.072000027-08:00</td>\n",
       "      <td>2021-06-03 05:25:19.072000027-08:00</td>\n",
       "      <td>2021-05-26 15:52:20.006000042-08:00</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>2021-05-26 15:50:00-08:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>215 rows Ã— 18 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                           CreationDate                            EditDate  \\\n",
       "0   2020-02-19 01:27:35.359999895+00:00 2020-03-04 20:01:31.436000109+00:00   \n",
       "1   2020-02-19 01:27:41.535000086+00:00 2020-02-19 01:27:41.535000086+00:00   \n",
       "2   2020-02-19 01:27:44.867000103+00:00 2020-02-19 01:27:44.867000103+00:00   \n",
       "3   2020-02-19 01:27:48.403000116+00:00 2020-02-19 01:27:48.403000116+00:00   \n",
       "4   2020-02-19 01:27:55.072999954+00:00 2020-02-19 05:24:42.161000013+00:00   \n",
       "..                                  ...                                 ...   \n",
       "210 2021-06-03 13:24:29.697000027+00:00 2021-06-03 13:24:29.697000027+00:00   \n",
       "211 2021-06-03 13:24:46.849999905+00:00 2021-06-03 13:24:46.849999905+00:00   \n",
       "212 2021-06-03 13:24:56.306999922+00:00 2021-06-03 13:24:56.306999922+00:00   \n",
       "213 2021-06-03 13:25:09.088999987+00:00 2021-06-03 13:25:09.088999987+00:00   \n",
       "214 2021-06-03 13:25:19.072000027+00:00 2021-06-03 13:25:19.072000027+00:00   \n",
       "\n",
       "                            todays_date       UTC_Time_Measured_4  \\\n",
       "0             2020-02-18 20:00:00+00:00 2020-02-18 20:30:00+00:00   \n",
       "1             2020-02-18 20:00:00+00:00                       NaT   \n",
       "2             2020-02-18 20:00:00+00:00                       NaT   \n",
       "3             2020-02-18 20:00:00+00:00                       NaT   \n",
       "4             2020-02-18 20:00:00+00:00                       NaT   \n",
       "..                                  ...                       ...   \n",
       "210 2021-05-17 23:58:09.528000115+00:00                       NaT   \n",
       "211 2021-05-26 23:34:45.665999889+00:00 2021-05-26 23:35:00+00:00   \n",
       "212 2021-05-26 23:39:50.819999933+00:00                       NaT   \n",
       "213           2021-05-26 19:00:00+00:00                       NaT   \n",
       "214 2021-05-26 23:52:20.006000042+00:00                       NaT   \n",
       "\n",
       "                    UTC_Time_Measured_1                 UTC_Time_Measured_2  \\\n",
       "0                                   NaT                                 NaT   \n",
       "1                                   NaT 2020-02-18 20:34:09.976000071+00:00   \n",
       "2                                   NaT                                 NaT   \n",
       "3                                   NaT                                 NaT   \n",
       "4   2020-02-18 20:00:34.260999918+00:00                                 NaT   \n",
       "..                                  ...                                 ...   \n",
       "210                                 NaT                                 NaT   \n",
       "211                                 NaT                                 NaT   \n",
       "212                                 NaT                                 NaT   \n",
       "213                                 NaT                                 NaT   \n",
       "214                                 NaT                                 NaT   \n",
       "\n",
       "            time_logger_pulled_UTC_time       time_logger_re_deployed_UTC_t  \\\n",
       "0                                   NaT                                 NaT   \n",
       "1             2020-02-18 20:33:00+00:00           2020-02-18 20:38:00+00:00   \n",
       "2   2020-02-18 20:26:40.049999952+00:00           2020-02-18 20:27:00+00:00   \n",
       "3   2020-02-18 20:23:44.302999973+00:00           2020-02-18 20:24:00+00:00   \n",
       "4             2020-02-18 20:03:00+00:00 2020-02-18 20:11:21.598999977+00:00   \n",
       "..                                  ...                                 ...   \n",
       "210                                 NaT                                 NaT   \n",
       "211                                 NaT                                 NaT   \n",
       "212                                 NaT                                 NaT   \n",
       "213                                 NaT                                 NaT   \n",
       "214                                 NaT                                 NaT   \n",
       "\n",
       "                    UTC_Time_Measured_3                    CreationDate_PST  \\\n",
       "0                                   NaT 2020-02-18 17:27:35.359999895-08:00   \n",
       "1                                   NaT 2020-02-18 17:27:41.535000086-08:00   \n",
       "2                                   NaT 2020-02-18 17:27:44.867000103-08:00   \n",
       "3                                   NaT 2020-02-18 17:27:48.403000116-08:00   \n",
       "4                                   NaT 2020-02-18 17:27:55.072999954-08:00   \n",
       "..                                  ...                                 ...   \n",
       "210 2021-05-17 23:58:20.746999979+00:00 2021-06-03 05:24:29.697000027-08:00   \n",
       "211                                 NaT 2021-06-03 05:24:46.849999905-08:00   \n",
       "212           2021-05-26 23:40:00+00:00 2021-06-03 05:24:56.306999922-08:00   \n",
       "213           2021-05-26 23:43:00+00:00 2021-06-03 05:25:09.088999987-08:00   \n",
       "214           2021-05-26 23:50:00+00:00 2021-06-03 05:25:19.072000027-08:00   \n",
       "\n",
       "                           EditDate_PST                     todays_date_PST  \\\n",
       "0   2020-03-04 12:01:31.436000109-08:00           2020-02-18 12:00:00-08:00   \n",
       "1   2020-02-18 17:27:41.535000086-08:00           2020-02-18 12:00:00-08:00   \n",
       "2   2020-02-18 17:27:44.867000103-08:00           2020-02-18 12:00:00-08:00   \n",
       "3   2020-02-18 17:27:48.403000116-08:00           2020-02-18 12:00:00-08:00   \n",
       "4   2020-02-18 21:24:42.161000013-08:00           2020-02-18 12:00:00-08:00   \n",
       "..                                  ...                                 ...   \n",
       "210 2021-06-03 05:24:29.697000027-08:00 2021-05-17 15:58:09.528000115-08:00   \n",
       "211 2021-06-03 05:24:46.849999905-08:00 2021-05-26 15:34:45.665999889-08:00   \n",
       "212 2021-06-03 05:24:56.306999922-08:00 2021-05-26 15:39:50.819999933-08:00   \n",
       "213 2021-06-03 05:25:09.088999987-08:00           2021-05-26 11:00:00-08:00   \n",
       "214 2021-06-03 05:25:19.072000027-08:00 2021-05-26 15:52:20.006000042-08:00   \n",
       "\n",
       "      UTC_Time_Measured_4_PST             UTC_Time_Measured_1_PST  \\\n",
       "0   2020-02-18 12:30:00-08:00                                 NaT   \n",
       "1                         NaT                                 NaT   \n",
       "2                         NaT                                 NaT   \n",
       "3                         NaT                                 NaT   \n",
       "4                         NaT 2020-02-18 12:00:34.260999918-08:00   \n",
       "..                        ...                                 ...   \n",
       "210                       NaT                                 NaT   \n",
       "211 2021-05-26 15:35:00-08:00                                 NaT   \n",
       "212                       NaT                                 NaT   \n",
       "213                       NaT                                 NaT   \n",
       "214                       NaT                                 NaT   \n",
       "\n",
       "                UTC_Time_Measured_2_PST     time_logger_pulled_UTC_time_PST  \\\n",
       "0                                   NaT                                 NaT   \n",
       "1   2020-02-18 12:34:09.976000071-08:00           2020-02-18 12:33:00-08:00   \n",
       "2                                   NaT 2020-02-18 12:26:40.049999952-08:00   \n",
       "3                                   NaT 2020-02-18 12:23:44.302999973-08:00   \n",
       "4                                   NaT           2020-02-18 12:03:00-08:00   \n",
       "..                                  ...                                 ...   \n",
       "210                                 NaT                                 NaT   \n",
       "211                                 NaT                                 NaT   \n",
       "212                                 NaT                                 NaT   \n",
       "213                                 NaT                                 NaT   \n",
       "214                                 NaT                                 NaT   \n",
       "\n",
       "      time_logger_re_deployed_UTC_t_PST             UTC_Time_Measured_3_PST  \n",
       "0                                   NaT                                 NaT  \n",
       "1             2020-02-18 12:38:00-08:00                                 NaT  \n",
       "2             2020-02-18 12:27:00-08:00                                 NaT  \n",
       "3             2020-02-18 12:24:00-08:00                                 NaT  \n",
       "4   2020-02-18 12:11:21.598999977-08:00                                 NaT  \n",
       "..                                  ...                                 ...  \n",
       "210                                 NaT 2021-05-17 15:58:20.746999979-08:00  \n",
       "211                                 NaT                                 NaT  \n",
       "212                                 NaT           2021-05-26 15:40:00-08:00  \n",
       "213                                 NaT           2021-05-26 15:43:00-08:00  \n",
       "214                                 NaT           2021-05-26 15:50:00-08:00  \n",
       "\n",
       "[215 rows x 18 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check datetime data\n",
    "sedfHydroAllData.select_dtypes(include=['datetime64[ns, UTC]','datetime64[ns, US/Pacific]'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert Python date time into format Excel can read more easily\n",
    "datetimefield_list = sedfHydroAllData[['CreationDate', 'EditDate', 'CreationDate_PST', 'EditDate_PST']]\n",
    "\n",
    "for col in datetimefield_list:\n",
    "    sedfHydroAllData[col] = sedfHydroAllData[col].dt.strftime('%m/%d/%Y %H:%M:%S %Z%z')\n",
    "\n",
    "datefield_list = sedfHydroAllData[['todays_date', 'todays_date_PST']]\n",
    "\n",
    "for col in datefield_list:\n",
    "    sedfHydroAllData[col] = sedfHydroAllData[col].dt.strftime('%m/%d/%Y')\n",
    "\n",
    "timefield_list = sedfHydroAllData[['UTC_Time_Measured_4', 'UTC_Time_Measured_1', 'UTC_Time_Measured_2', 'time_logger_pulled_UTC_time', 'time_logger_re_deployed_UTC_t', 'UTC_Time_Measured_3', 'UTC_Time_Measured_4_PST', 'UTC_Time_Measured_1_PST', 'UTC_Time_Measured_2_PST', 'time_logger_pulled_UTC_time_PST', 'time_logger_re_deployed_UTC_t_PST', 'UTC_Time_Measured_3_PST']]\n",
    "\n",
    "for col in timefield_list:\n",
    "    sedfHydroAllData[col] = sedfHydroAllData[col].dt.strftime('%H:%M')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Subset data for Dempsey Creek Staff Gage at Wilson Dairy, Nisqually NWR\n",
    "\n",
    "# Select data based on 2 conditions: measurement type = piezometer and location = dempsey creek gauge OR measurement type = dempsey creek level quick survey\n",
    "sedfHydroStaffGageData = sedfHydroAllData.loc[((sedfHydroAllData['Measurement_Type'] == \"piezometers\") & (sedfHydroAllData['Location__logger'] == \"dempsey_creek_gauge\")) | ((sedfHydroAllData['Measurement_Type'] == \"dempsey_creek_level_quick_surve\"))]\n",
    "\n",
    "# Select columns and reset in desired order\n",
    "sedfHydroStaffGageData = sedfHydroStaffGageData[['todays_date_PST', 'UTC_Time_Measured_4_PST', 'observers', 'observers_other', 'creek_gauge_ft', 'UTC_Time_Measured_2_PST', 'staff_gauge_ht_ft', 'data_downloaded', 'logger_serial', 'time_logger_pulled_UTC_time_PST', 'time_logger_re_deployed_UTC_t_PST', 'battery', 'additional_notes', 'globalid', 'SHAPE']]\n",
    "\n",
    "# Rename columns\n",
    "sedfHydroStaffGageData.rename(columns = {'todays_date_PST':'Date', 'UTC_Time_Measured_4_PST':'Time Gauge Reading (PST)', 'observers':'Observers', 'observers_other':'Other Observers', 'creek_gauge_ft':'Gauge Water Level (ft)', 'UTC_Time_Measured_2_PST':'Time Outside Staff Reading (PST)', 'staff_gauge_ht_ft':'Outside Staff Reading (ft)', 'data_downloaded':'Downloaded Data', 'logger_serial':'Logger Serial#', 'time_logger_pulled_UTC_time_PST':'Time Logger Pulled (PST)', 'time_logger_re_deployed_UTC_t_PST':'Time Logger Re-deployed (PST)', 'battery':'Battery', 'additional_notes':'Notes', 'globalid':'GlobalID', 'SHAPE':'SHAPE'}, inplace= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Subset data for piezometer Piez P1 East at Wilson Dairy, Nisqually NWR\n",
    "\n",
    "# Select data based on 2 conditions: measurement type = piezometer and location = piezometer_1_east\n",
    "sedfHydroPiezP1EastData = sedfHydroAllData.loc[((sedfHydroAllData['Measurement_Type'] == \"piezometers\") & (sedfHydroAllData['Location__logger'] == \"piezometer_1_east\"))]\n",
    "\n",
    "# Select columns and reset in desired order\n",
    "sedfHydroPiezP1EastData = sedfHydroPiezP1EastData[['todays_date_PST', 'UTC_Time_Measured_1_PST', 'observers', 'observers_other', 'depth_to_water_level_inside_wel', 'depth_to_water_outside_well_ft', 'depth_to_ground_level_inside_we', 'depth_to_ground_outside_well_ft', 'data_downloaded', 'logger_serial', 'time_logger_pulled_UTC_time_PST', 'time_logger_re_deployed_UTC_t_PST', 'battery', 'additional_notes', 'globalid', 'SHAPE']]\n",
    "\n",
    "# Calculate Height of water above HOBO (length of stick = 6.20')\n",
    "lengthofstickP1 = 6.2\n",
    "sedfHydroPiezP1EastData['Height of water above HOBO (Ft; length of stick = 6.20)'] = lengthofstickP1 - sedfHydroPiezP1EastData['depth_to_water_level_inside_wel']\n",
    "\n",
    "# Rename columns\n",
    "sedfHydroPiezP1EastData.rename(columns = {'todays_date_PST':'Date', 'UTC_Time_Measured_1_PST':'Time Measurement (PST)', 'observers':'Observers', 'observers_other':'Other Observers', 'depth_to_water_level_inside_wel':'Depth to Water Level Inside Well (Ft)', 'depth_to_water_outside_well_ft':'Depth to Water Outside Well (Ft)', 'depth_to_ground_level_inside_we':'Depth to Ground Level Inside Well (Ft)', 'depth_to_ground_outside_well_ft':'Depth to Ground Outside Well (Ft)', 'data_downloaded':'Downloaded Data', 'logger_serial':'Logger Serial#', 'time_logger_pulled_UTC_time_PST':'Time Logger Pulled (PST)', 'time_logger_re_deployed_UTC_t_PST':'Time Logger Re-deployed (PST)', 'battery':'Battery', 'additional_notes':'Notes', 'globalid':'GlobalID', 'SHAPE':'SHAPE'}, inplace= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Subset data for piezometer Piez P2 Central at Wilson Dairy, Nisqually NWR\n",
    "\n",
    "# Select data based on 2 conditions: measurement type = piezometer and location = piezometer_1_east\n",
    "sedfHydroPiezP2CentralData = sedfHydroAllData.loc[((sedfHydroAllData['Measurement_Type'] == \"piezometers\") & (sedfHydroAllData['Location__logger'] == \"piezometer_2_central\"))]\n",
    "\n",
    "# Select columns and reset in desired order\n",
    "sedfHydroPiezP2CentralData = sedfHydroPiezP2CentralData[['todays_date_PST', 'UTC_Time_Measured_1_PST', 'observers', 'observers_other', 'depth_to_water_level_inside_wel', 'depth_to_water_outside_well_ft', 'depth_to_ground_level_inside_we', 'depth_to_ground_outside_well_ft', 'data_downloaded', 'logger_serial', 'time_logger_pulled_UTC_time_PST', 'time_logger_re_deployed_UTC_t_PST', 'battery', 'additional_notes', 'globalid', 'SHAPE']]\n",
    "\n",
    "# Calculate Height of water above HOBO (length of stick = 6.20')\n",
    "lengthofstickP2 = 6.2\n",
    "sedfHydroPiezP2CentralData['Height of water above HOBO (Ft; length of stick = 6.20)'] = lengthofstickP2 - sedfHydroPiezP2CentralData['depth_to_water_level_inside_wel']\n",
    "\n",
    "# Rename columns\n",
    "sedfHydroPiezP2CentralData.rename(columns = {'todays_date_PST':'Date', 'UTC_Time_Measured_1_PST':'Time Measurement (PST)', 'observers':'Observers', 'observers_other':'Other Observers', 'depth_to_water_level_inside_wel':'Depth to Water Level Inside Well (Ft)', 'depth_to_water_outside_well_ft':'Depth to Water Outside Well (Ft)', 'depth_to_ground_level_inside_we':'Depth to Ground Level Inside Well (Ft)', 'depth_to_ground_outside_well_ft':'Depth to Ground Outside Well (Ft)', 'data_downloaded':'Downloaded Data', 'logger_serial':'Logger Serial#', 'time_logger_pulled_UTC_time_PST':'Time Logger Pulled (PST)', 'time_logger_re_deployed_UTC_t_PST':'Time Logger Re-deployed (PST)', 'battery':'Battery', 'additional_notes':'Notes', 'globalid':'GlobalID', 'SHAPE':'SHAPE'}, inplace= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Subset data for piezometer Piez P3 West at Wilson Dairy, Nisqually NWR\n",
    "\n",
    "# Select data based on 2 conditions: measurement type = piezometer and location = piezometer_3_west\n",
    "sedfHydroPiezP3WestData = sedfHydroAllData.loc[((sedfHydroAllData['Measurement_Type'] == \"piezometers\") & (sedfHydroAllData['Location__logger'] == \"piezometer_3_west\"))]\n",
    "\n",
    "# Select columns and reset in desired order\n",
    "sedfHydroPiezP3WestData = sedfHydroPiezP3WestData[['todays_date_PST', 'UTC_Time_Measured_1_PST', 'observers', 'observers_other', 'depth_to_water_level_inside_wel', 'depth_to_water_outside_well_ft', 'depth_to_ground_level_inside_we', 'depth_to_ground_outside_well_ft', 'data_downloaded', 'logger_serial', 'time_logger_pulled_UTC_time_PST', 'time_logger_re_deployed_UTC_t_PST', 'battery', 'additional_notes', 'globalid', 'SHAPE']]\n",
    "\n",
    "# Calculate Height of water above HOBO (length of stick = 5.65')\n",
    "lengthofstickP3 = 5.65\n",
    "sedfHydroPiezP3WestData['Height of water above HOBO (Ft; length of stick = 5.65)'] = lengthofstickP3 - sedfHydroPiezP3WestData['depth_to_water_level_inside_wel']\n",
    "\n",
    "# Rename columns\n",
    "sedfHydroPiezP3WestData.rename(columns = {'todays_date_PST':'Date', 'UTC_Time_Measured_1_PST':'Time Measurement (PST)', 'observers':'Observers', 'observers_other':'Other Observers', 'depth_to_water_level_inside_wel':'Depth to Water Level Inside Well (Ft)', 'depth_to_water_outside_well_ft':'Depth to Water Outside Well (Ft)', 'depth_to_ground_level_inside_we':'Depth to Ground Level Inside Well (Ft)', 'depth_to_ground_outside_well_ft':'Depth to Ground Outside Well (Ft)', 'data_downloaded':'Downloaded Data', 'logger_serial':'Logger Serial#', 'time_logger_pulled_UTC_time_PST':'Time Logger Pulled (PST)', 'time_logger_re_deployed_UTC_t_PST':'Time Logger Re-deployed (PST)', 'battery':'Battery', 'additional_notes':'Notes', 'globalid':'GlobalID', 'SHAPE':'SHAPE'}, inplace= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "### Create export paths\n",
    "writer = pd.ExcelWriter(os.path.join(out_workspace,(timestamp + '_WilsonDairyHydro.xlsx')))\n",
    "metadata.to_excel(writer, 'Metadata')\n",
    "sedfHydroStaffGageData.to_excel(writer, 'Staff Gage')\n",
    "sedfHydroPiezP1EastData.to_excel(writer, 'Piez P1 East')\n",
    "sedfHydroPiezP2CentralData.to_excel(writer, 'Piez P2 Central')\n",
    "sedfHydroPiezP3WestData.to_excel(writer, 'Piez P3 West')\n",
    "sedfHydroAllData.to_excel(writer, (timestamp + \" AGOL Data\"))\n",
    "writer.save()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
